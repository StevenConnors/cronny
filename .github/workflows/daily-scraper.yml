name: Daily Web Scraper

on:
  schedule:
    - cron: '0 15 * * *'
  workflow_dispatch:

permissions:
  contents: write
  issues: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install -r requirements.txt
      - env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        run: python scripts/fetch_and_parse.py --input inputs.json

      - name: Check for changes
        id: changes
        run: |
          if [ -f changes.json ]; then
            echo "changes=true" >> $GITHUB_OUTPUT
          else
            echo "changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Create GitHub issues for changes
        if: steps.changes.outputs.changes == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const changes = JSON.parse(fs.readFileSync('changes.json', 'utf-8'));
            let body = '';
            const today = new Date().toISOString().slice(0, 10); // YYYY-MM-DD
            for (const change of changes) {
              body += `- **Topic:** ${change.topic}\n  **URL:** ${change.url}\n  **Change:** ${change.title}\n\n`;
            }
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `(${today}) Web Scraper: Updates Detected`,
              body: body
            });

      - name: Commit and push latest results
        if: steps.changes.outputs.changes == 'true'
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add latest_results.json
          git commit -m "Update latest results [skip ci]" || echo "No changes to commit"
          git push
    